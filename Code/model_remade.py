# -*- coding: utf-8 -*-
"""Copy of Model Remade.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_drd65TmuPV9hEzPW8DYGncxMjFsAi-M

###MODEL OF CNN
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
import keras
# %matplotlib inline
#import utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D
from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import plot_model
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from IPython.display import SVG, Image

img_size=48 #converting img into array size of 48
batch_size=32


#we have 3 sets of convolutions followed by pooling input shape is 48 by 48
#we will define a sequential layer
model = Sequential()
#32 filters with 3x3 matrix of pixels which generate dot product with the random 3x3 matrix, done for all 32 filters 
# Note the input shape is the desired size of the input image 128,1288 with 3 bytes color
model.add(Conv2D(32,kernel_size= (3, 3), activation='relu',input_shape=( 128, 128,3),padding='same'))
model.add(Conv2D(64,kernel_size= (3, 3), activation='relu',padding='same'))

model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))#reduce image size and overfitting
model.add(Dropout(0.25))
model.add(Conv2D(64,kernel_size= (3, 3), activation='relu',padding='same'))
model.add(Conv2D(64,kernel_size= (3, 3), activation='relu',padding='same'))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dense(3)) #because of 3 classes
model.add(Activation('softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adam(),
              metrics=['accuracy'])
model.summary()

"""###25 Epochs"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
# %matplotlib inline
#import utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D
from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import plot_model
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.callbacks import *
from IPython.display import SVG, Image
#from livelossplot import PlotLossesTensorFlowKeras
#from Keras import backend as K
#K.common.image_dim_ordering()
#K.common.set_image_dim_ordering(dim_ordering)


img_size=128
batch_size=32

datagen_train=ImageDataGenerator(horizontal_flip=True,height_shift_range=0.05, 
                                 width_shift_range=0.05, fill_mode='constant', 
                                  zoom_range=0.05,validation_split=0.2,cval =0.1,rotation_range=8)
train_generator=datagen_train.flow_from_directory("/content/drive/My Drive/Dataset/Augmented train ",target_size=(img_size,img_size), batch_size=batch_size,class_mode='categorical', shuffle=True )
train_generator=datagen_train.flow_from_directory("/content/drive/My Drive/Dataset/Augmented train ",target_size=(img_size,img_size), batch_size=batch_size,class_mode='categorical', shuffle=True,subset='training' )
#TEST
datagen_validation=ImageDataGenerator(horizontal_flip=True)
validation_generator=datagen_train.flow_from_directory("/content/drive/My Drive/Dataset/Augmented train ",target_size=(img_size,img_size), batch_size=batch_size,class_mode='categorical', subset='validation')
#filepath = "/content/drive/My Drive/MyCNN/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5"
#checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')
#callbacks_list = [checkpoint]
history=model.fit(x=train_generator,epochs=25,verbose=1, validation_data=validation_generator)#,callbacks=callbacks_list
score = model.evaluate( validation_generator, verbose=1)
print('Test loss: {score[0]} / Test accuracy: {score[1]}')

# Visualize history
# Plot history: val_Loss
plt.plot(history.history['val_loss'])
plt.title('Validation loss history')
plt.ylabel('Loss value')
plt.xlabel('No. epoch')
plt.show()
"""
#Plot history: val_Accuracy
plt.plot(history.history['val_accuracy'])
plt.title('Validation accuracy history')
plt.ylabel('Accuracy value (%)')
plt.xlabel('No. epoch')
plt.show()

#Plot history: loss
plt.plot(history.history['loss'])
plt.title('loss history')
plt.ylabel('Loss value')
plt.xlabel('No. epoch')
plt.show()

#Plot history: Accuracy
plt.plot(history.history['accuracy'])
plt.title('accuracy history')
plt.ylabel('Accuracy value (%)')
plt.xlabel('No. epoch')
plt.show()
"""
# Visualize history
#Plot history: for Accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy value %')
plt.xlabel('No. epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot history: for Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss value')
plt.xlabel('No. epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""###Confusion Matrix """

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
# %matplotlib inline
#import utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D
from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import plot_model
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.callbacks import *
from IPython.display import SVG, Image
img_size=128
batch_size=32

datagen_train=ImageDataGenerator()#horizontal_flip=True,height_shift_range=0.05, 
                                 #width_shift_range=0.05, fill_mode='constant', 
                                  #zoom_range=0.05,validation_split=0.2,cval =0.1,rotation_range=8)
train_generator=datagen_train.flow_from_directory("/content/drive/MyDrive/Dataset/Model Evaluate",target_size=(img_size,img_size), batch_size=batch_size,class_mode='categorical', shuffle=False )
test_steps_per_epoch = np.math.ceil(train_generator.samples / train_generator.batch_size)
predictions = model.predict(train_generator, steps=test_steps_per_epoch)
predicted_classes = np.argmax(predictions, axis=1)

true_classes = train_generator.classes
class_labels = list(train_generator.class_indices.keys())

import sklearn.metrics as metrics
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model, Sequential
from sklearn.metrics import ConfusionMatrixDisplay
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import plot_model
from keras.models import Sequential
report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)
print(report) 
cm=confusion_matrix(true_classes, predicted_classes)
#cm1=plot_confusion_matrix(true_classes,predicted_classes,class_labels,cmap=plt.cm.Blues)
print(cm)
cm_display = ConfusionMatrixDisplay(cm,class_labels).plot()
#print(cm1)

"""### 50 epochs"""

# Commented out IPython magic to ensure Python compatibility.

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os
# %matplotlib inline
#import utils
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D
from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import plot_model
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from IPython.display import SVG, Image
#from livelossplot import PlotLossesTensorFlowKeras
#from Keras import backend as K
#K.common.image_dim_ordering()
#K.common.set_image_dim_ordering(dim_ordering)


img_size=128
batch_size=32

datagen_train=ImageDataGenerator(horizontal_flip=True,height_shift_range=0.05, 
                                 width_shift_range=0.05, fill_mode='constant', 
                                  zoom_range=0.05,validation_split=0.2,cval =0.1,rotation_range=8)
train_generator=datagen_train.flow_from_directory("/content/drive/My Drive/Dataset/Augmented train ",target_size=(img_size,img_size), batch_size=batch_size,class_mode='categorical', shuffle=True )
train_generator=datagen_train.flow_from_directory("/content/drive/My Drive/Dataset/Augmented train ",target_size=(img_size,img_size), batch_size=batch_size,class_mode='categorical', shuffle=True,subset='training' )
#TEST
datagen_validation=ImageDataGenerator(horizontal_flip=True)
validation_generator=datagen_train.flow_from_directory("/content/drive/My Drive/Dataset/Augmented train ",target_size=(img_size,img_size), batch_size=batch_size,class_mode='categorical', subset='validation')

history=model.fit(x=train_generator,epochs=50,verbose=1, validation_data=validation_generator)
score = model.evaluate( validation_generator, verbose=1)
print('Test loss: {score[0]} / Test accuracy: {score[1]}')

# Visualize history
#Plot history: for Accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy value %')
plt.xlabel('No. epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot history: for Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss value')
plt.xlabel('No. epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()